import json
import re
from io import BytesIO
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

st.set_page_config(page_title="Ğ­Ğ—Ğ¡ â€” Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹", layout="wide")


# =========================
# Defaults
# =========================
DEFAULT_SHEET_ID = "1YN_8UtrZMqOTYZHaLzczwkkfocD-sS_wKrlSBmn-S50"
DEFAULT_GID = "2075524941"

DEFAULT_THEME_RULES = [
    {"theme": "ĞœĞ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ", "keywords": ["Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½", "Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶"]},
    {"theme": "Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞµÑÑĞ¸Ğ¸ / ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "keywords": ["Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚", "Ğ·Ğ°Ğ¿ÑƒÑĞº", "Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°", "ÑĞµÑÑĞ¸"]},
    {"theme": "ĞŸÑ€ĞµÑ€Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞµÑÑĞ¸Ğ¸", "keywords": ["Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°Ğ½", "ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ»ÑŒĞ½"]},
    {"theme": "ĞŸĞ»Ğ°Ñ‚ĞµĞ¶Ğ¸ / Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ", "keywords": ["Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½", "Ğ±Ğ°Ğ½ĞºĞ¾Ğ²ÑĞº", "Ğ±Ğ°Ğ»Ğ°Ğ½Ñ", "Ğ´ĞµĞ½ĞµĞ¶", "Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚"]},
    {"theme": "Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ/Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ", "keywords": ["Ğ½Ğ¸Ğ·ĞºĞ°Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ", "Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾", "Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚"]},
    {"theme": "ĞÑ„Ñ„Ğ»Ğ°Ğ¹Ğ½/ÑĞµÑ‚ÑŒ/Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ", "keywords": ["Ğ½Ğµ Ğ² ÑĞµÑ‚Ğ¸", "Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿", "Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³"]},
    {"theme": "ĞŸĞ°Ñ€ĞºĞ¾Ğ²ĞºĞ°/Ğ·Ğ°Ğ½ÑÑ‚Ğ¾", "keywords": ["Ğ¿Ğ°Ñ€ĞºĞ¾Ğ²", "Ğ·Ğ°Ğ½ÑÑ‚Ğ¾", "Ğ´Ğ²Ñ", "Ğ¿Ğ´Ğ´"]},
    {"theme": "ĞšĞ¾Ğ½Ğ½ĞµĞºÑ‚Ğ¾Ñ€Ñ‹/ĞºĞ½Ğ¾Ğ¿ĞºĞ°", "keywords": ["ĞºĞ¾Ğ½Ğ½ĞµĞºÑ‚Ğ¾Ñ€", "Ğ°Ğ²Ğ°Ñ€Ğ¸Ğ¹Ğ½", "ĞºĞ½Ğ¾Ğ¿Ğº"]},
    {"theme": "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ­Ğ—Ğ¡", "keywords": ["ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğº", "Ñ‚ĞµÑ€Ñ€Ğ¸Ñ‚Ğ¾Ñ€Ğ¸"]},
]


# =========================
# Helpers (safe / robust)
# =========================
def gsheets_csv_url(sheet_id: str, gid: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"


def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", str(s).strip()).lower()


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [re.sub(r"\s+", " ", str(c).strip()) for c in df.columns]
    return df


def pick_col(columns: List[str], candidates: List[str]) -> Optional[str]:
    if not columns:
        return None
    norm_cols = {_norm(c): c for c in columns}
    for cand in candidates:
        key = _norm(cand)
        if key in norm_cols:
            return norm_cols[key]
    # partial match fallback
    for cand in candidates:
        key = _norm(cand)
        for n, orig in norm_cols.items():
            if key and key in n:
                return orig
    return None


def safe_stop(msg: str, details: Optional[str] = None) -> None:
    st.error(msg)
    if details:
        with st.expander("ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸"):
            st.code(details)
    st.stop()


def read_table_from_upload(uploaded) -> pd.DataFrame:
    name = (uploaded.name or "").lower()
    data = uploaded.getvalue()
    try:
        if name.endswith(".xlsx") or name.endswith(".xls"):
            return pd.read_excel(BytesIO(data))
        # default: csv
        return pd.read_csv(BytesIO(data), on_bad_lines="skip")
    except Exception as e:
        safe_stop("ĞĞµ ÑĞ¼Ğ¾Ğ³ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ».", str(e))
    return pd.DataFrame()  # unreachable


@st.cache_data(ttl=600, show_spinner=False)
def load_from_gsheets(sheet_id: str, gid: str) -> pd.DataFrame:
    url = gsheets_csv_url(sheet_id, gid)
    # on_bad_lines='skip' Ğ·Ğ°Ñ‰Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¾Ñ‚ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… â€œĞ±Ğ¸Ñ‚Ñ‹Ñ…â€ ÑÑ‚Ñ€Ğ¾Ğº
    return pd.read_csv(url, on_bad_lines="skip")


def parse_dt(df: pd.DataFrame, col_date: str, col_time: Optional[str]) -> pd.Series:
    # Ğ’Ñ€ĞµĞ¼Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ â€” Ñ‚Ğ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ°Ñ‚Ñƒ
    if col_time:
        s = df[col_date].astype(str) + " " + df[col_time].astype(str)
    else:
        s = df[col_date].astype(str)
    dt = pd.to_datetime(s, dayfirst=True, errors="coerce")
    return dt


def classify_theme(text: str, rules: List[Dict]) -> str:
    t = _norm(text)
    for r in rules:
        theme = (r.get("theme", "") or "").strip() or "Ğ‘ĞµĞ· Ñ‚ĞµĞ¼Ñ‹"
        kws = r.get("keywords", []) or []
        for k in kws:
            if _norm(k) and _norm(k) in t:
                return theme
    return "Ğ”Ñ€ÑƒĞ³Ğ¾Ğµ"


def add_totals_crosstab(index: pd.Series, columns: pd.Series, total_name: str = "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾") -> pd.DataFrame:
    # ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°Ñ ÑĞ²Ğ¾Ğ´ĞºĞ°: Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ Ã— Ñ‚ĞµĞ¼Ğ°, Ñ Ğ¸Ñ‚Ğ¾Ğ³Ğ°Ğ¼Ğ¸
    idx = index.fillna("â€”").astype(str)
    col = columns.fillna("â€”").astype(str)
    ct = pd.crosstab(idx, col, dropna=False)
    ct[total_name] = ct.sum(axis=1)
    total_row = ct.sum(axis=0).to_frame().T
    total_row.index = [total_name]
    out = pd.concat([ct, total_row], axis=0).reset_index().rename(columns={"index": "ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ"})
    return out


def to_excel_bytes(sheets: Dict[str, pd.DataFrame]) -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as w:
        for name, sdf in sheets.items():
            sdf.to_excel(w, sheet_name=name[:31], index=False)
    return bio.getvalue()


# =========================
# UI: source
# =========================
st.title("ğŸ“Š Ğ­Ğ—Ğ¡ â€” Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹ (safe)")

with st.sidebar:
    st.header("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº")
    mode = st.radio("ĞÑ‚ĞºÑƒĞ´Ğ° Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ?", ["Google Sheets (Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ)", "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» (CSV/Excel)"])

    sheet_id = DEFAULT_SHEET_ID
    gid = DEFAULT_GID
    uploaded = None

    if mode == "Google Sheets (Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ)":
        sheet_id = st.text_input("Google Sheet ID", value=DEFAULT_SHEET_ID)
        gid = st.text_input("GID (Ğ»Ğ¸ÑÑ‚)", value=DEFAULT_GID)
        st.caption("Ğ•ÑĞ»Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚: Ğ¾Ñ‚ĞºÑ€Ğ¾Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ â€œAnyone with the link â†’ Viewerâ€ Ğ¸Ğ»Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸ CSV/Excel.")
        if st.button("ğŸ”„ Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ ĞºÑÑˆ"):
            st.cache_data.clear()
            st.toast("ĞšÑÑˆ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½.", icon="âœ…")
    else:
        uploaded = st.file_uploader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸ CSV Ğ¸Ğ»Ğ¸ Excel", type=["csv", "xlsx", "xls"])

    st.divider()
    st.header("Ğ¢ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸")
    rules_text = st.text_area(
        "ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° (JSON). ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ.",
        value=json.dumps(DEFAULT_THEME_RULES, ensure_ascii=False, indent=2),
        height=240,
    )
    try:
        theme_rules = json.loads(rules_text)
        if not isinstance(theme_rules, list):
            raise ValueError("JSON Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ¼.")
    except Exception as e:
        st.warning(f"JSON Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ» ÑĞ»Ğ¾Ğ¼Ğ°Ğ½ â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚. ({e})")
        theme_rules = DEFAULT_THEME_RULES


# =========================
# Load
# =========================
try:
    if mode == "Google Sheets (Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ)":
        raw = load_from_gsheets(sheet_id, gid)
    else:
        if not uploaded:
            st.info("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸ Ñ„Ğ°Ğ¹Ğ», Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ.")
            st.stop()
        raw = read_table_from_upload(uploaded)
except Exception as e:
    safe_stop(
        "ĞĞµ ÑĞ¼Ğ¾Ğ³ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.",
        "Ğ§Ğ°ÑÑ‚Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:\n"
        "1) Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ½Ğµ Ñ€Ğ°ÑÑˆĞ°Ñ€ĞµĞ½Ğ° (Ğ½ÑƒĞ¶ĞµĞ½ public viewer)\n"
        "2) ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Sheet ID / GID\n"
        "3) Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞ±Ğ¾Ğ¹/Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Google\n\n"
        f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}",
    )

if raw is None or len(raw) == 0:
    safe_stop("Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¿ÑƒÑÑ‚Ğ°Ñ Ğ¸Ğ»Ğ¸ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ»Ğ°ÑÑŒ (0 ÑÑ‚Ñ€Ğ¾Ğº).")

df = normalize_columns(raw)

# =========================
# Column mapping (auto + manual fallback)
# =========================
cols = df.columns.tolist()

auto_date = pick_col(cols, ["Ğ”Ğ°Ñ‚Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "Ğ”Ğ°Ñ‚Ğ°", "Date"])
auto_time = pick_col(cols, ["Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "Ğ’Ñ€ĞµĞ¼Ñ", "Time"])
auto_reason = pick_col(cols, ["ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", "Ğ¢ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])
auto_station = pick_col(cols, ["ĞĞ¾Ğ¼ĞµÑ€ Ğ­Ğ—Ğ¡", "Ğ­Ğ—Ğ¡", "Station", "Ğ¡Ñ‚Ğ°Ğ½Ñ†Ğ¸Ñ"])
auto_vendor = pick_col(cols, ["ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ğ¸", "ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ", "Vendor"])
auto_note = pick_col(cols, ["ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ", "ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹", "Note"])
auto_id = pick_col(cols, ["â„–", "N", "No", "ĞĞ¾Ğ¼ĞµÑ€", "ID"])

with st.expander("ğŸ› ï¸ Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° Ğ¸ ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº"):
    st.write("Ğ•ÑĞ»Ğ¸ Ğ°Ğ²Ñ‚Ğ¾-Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ°Ñ…Ğ½ÑƒĞ»Ğ¾ÑÑŒ â€” Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ.")
    c1, c2 = st.columns(2)
    with c1:
        col_date = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ”ĞĞ¢Ğ", options=cols, index=(cols.index(auto_date) if auto_date in cols else 0))
        col_time = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ’Ğ Ğ•ĞœĞ¯ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols, index=(1 + cols.index(auto_time) if auto_time in cols else 0))
        col_reason = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞŸĞ Ğ˜Ğ§Ğ˜ĞĞ", options=cols, index=(cols.index(auto_reason) if auto_reason in cols else 0))
    with c2:
        col_station = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞĞĞœĞ•Ğ  Ğ­Ğ—Ğ¡ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols, index=(1 + cols.index(auto_station) if auto_station in cols else 0))
        col_vendor = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞŸĞ ĞĞ˜Ğ—Ğ’ĞĞ”Ğ˜Ğ¢Ğ•Ğ›Ğ¬ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols, index=(1 + cols.index(auto_vendor) if auto_vendor in cols else 0))
        col_note = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞŸĞ Ğ˜ĞœĞ•Ğ§ĞĞĞ˜Ğ• (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols, index=(1 + cols.index(auto_note) if auto_note in cols else 0))
    st.caption("ĞŸĞµÑ€Ğ²Ñ‹Ğµ 10 ÑÑ‚Ñ€Ğ¾Ğº:")
    st.dataframe(df.head(10), use_container_width=True)

# normalize "â€” Ğ½ĞµÑ‚ â€”"
col_time = None if col_time == "â€” Ğ½ĞµÑ‚ â€”" else col_time
col_station = None if col_station == "â€” Ğ½ĞµÑ‚ â€”" else col_station
col_vendor = None if col_vendor == "â€” Ğ½ĞµÑ‚ â€”" else col_vendor
col_note = None if col_note == "â€” Ğ½ĞµÑ‚ â€”" else col_note

if not col_date or col_date not in df.columns:
    safe_stop("ĞĞµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ´Ğ°Ñ‚Ñ‹.")
if not col_reason or col_reason not in df.columns:
    safe_stop("ĞĞµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹/Ñ‚ĞµĞ¼Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ.")

# =========================
# Parse datetime + derived fields
# =========================
df["_dt"] = parse_dt(df, col_date, col_time)
if df["_dt"].isna().all():
    safe_stop(
        "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ñ‹/Ğ²Ñ€ĞµĞ¼Ñ (Ğ²ÑĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼Ğ¸).",
        "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ´Ğ°Ñ‚Ñ‹/Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ.\n"
        "Ğ¡Ğ¾Ğ²ĞµÑ‚: Ğ² Google Sheets Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ÑŒ Ñ‚Ğ¸Ğ¿ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ² 'Ğ”Ğ°Ñ‚Ğ°' Ğ¸ 'Ğ’Ñ€ĞµĞ¼Ñ', Ğ»Ğ¸Ğ±Ğ¾ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·Ğ¸ CSV Ğ¸ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ÑĞ½Ğ¾Ğ²Ğ°."
    )

df["Ğ¢ĞµĞ¼Ğ°"] = df[col_reason].astype(str).apply(lambda x: classify_theme(x, theme_rules))
df["_week_start"] = df["_dt"].dt.to_period("W-MON").dt.start_time
df["_week_label"] = df["_week_start"].dt.strftime("%Y-%m-%d")
df["_month_period"] = df["_dt"].dt.to_period("M")

# =========================
# Filters
# =========================
st.subheader("Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
c1, c2, c3, c4 = st.columns([1.2, 1.2, 1.2, 1.4])

latest_week = df["_week_label"].dropna().max()

with c1:
    period_mode = st.radio("ĞŸĞµÑ€Ğ¸Ğ¾Ğ´", ["ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ½ĞµĞ´ĞµĞ»Ñ", "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ½ĞµĞ´ĞµĞ»Ğ¸", "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚"], horizontal=False)

with c2:
    if period_mode == "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ½ĞµĞ´ĞµĞ»Ğ¸":
        week = st.selectbox("ĞĞµĞ´ĞµĞ»Ñ (Ğ¿Ğ¾Ğ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¸Ğº)", sorted(df["_week_label"].dropna().unique())[::-1], index=0)
    else:
        week = latest_week

with c3:
    if period_mode == "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚":
        min_dt = df["_dt"].min().date()
        max_dt = df["_dt"].max().date()
        start_date = st.date_input("Ğ¡ Ğ´Ğ°Ñ‚Ñ‹", value=min_dt)
        end_date = st.date_input("ĞŸĞ¾ Ğ´Ğ°Ñ‚Ñƒ", value=max_dt)
    else:
        start_date, end_date = None, None

with c4:
    theme_filter = st.multiselect(
        "Ğ¢ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸",
        options=sorted(df["Ğ¢ĞµĞ¼Ğ°"].dropna().unique()),
        default=[],
        placeholder="Ğ’ÑĞµ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸",
    )

vendor_filter = []
if col_vendor:
    vendor_filter = st.multiselect(
        "ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ",
        options=sorted(df[col_vendor].dropna().astype(str).unique()),
        default=[],
        placeholder="Ğ’ÑĞµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸",
    )

# apply filters
fdf = df
if period_mode in ("ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ½ĞµĞ´ĞµĞ»Ñ", "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ½ĞµĞ´ĞµĞ»Ğ¸") and week:
    fdf = fdf[fdf["_week_label"] == week]

if period_mode == "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚":
    # inclusive end date
    start = pd.to_datetime(start_date)
    end = pd.to_datetime(end_date) + pd.Timedelta(days=1)
    fdf = fdf[(fdf["_dt"] >= start) & (fdf["_dt"] < end)]

if theme_filter:
    fdf = fdf[fdf["Ğ¢ĞµĞ¼Ğ°"].isin(theme_filter)]

if vendor_filter and col_vendor:
    fdf = fdf[fdf[col_vendor].astype(str).isin(vendor_filter)]

# =========================
# KPIs
# =========================
k1, k2, k3, k4 = st.columns(4)
total = int(len(fdf))
uniq_station = int(fdf[col_station].nunique()) if col_station else 0
k1.metric("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹", f"{total}")
k2.metric("Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ­Ğ—Ğ¡", f"{uniq_station}" if col_station else "â€”")
k3.metric("Ğ¢Ğ¾Ğ¿-Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°", fdf["Ğ¢ĞµĞ¼Ğ°"].value_counts().index[0] if total else "â€”")
k4.metric("Ğ§Ğ°ÑÑ‚Ğ°Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", fdf[col_reason].value_counts().index[0] if total else "â€”")

st.divider()

# =========================
# Trend (all data)
# =========================
st.markdown("#### Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ½ĞµĞ´ĞµĞ»ÑĞ¼")
trend = (
    df.dropna(subset=["_week_start"])
      .groupby("_week_start")
      .size()
      .rename("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
      .reset_index()
      .sort_values("_week_start")
)
if len(trend):
    st.line_chart(trend.set_index("_week_start")["ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])
else:
    st.info("ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°.")

# =========================
# Themes breakdown (filtered)
# =========================
st.markdown("#### Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°Ğ¼ (Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ)")
theme_counts = fdf["Ğ¢ĞµĞ¼Ğ°"].value_counts().rename_axis("Ğ¢ĞµĞ¼Ğ°").reset_index(name="ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
st.dataframe(theme_counts, use_container_width=True, hide_index=True)
if len(theme_counts):
    st.bar_chart(theme_counts.set_index("Ğ¢ĞµĞ¼Ğ°")["ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])

st.divider()

# =========================
# Vendor x Theme (filtered)
# =========================
st.markdown("#### ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸ Ã— Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ (Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ)")
vendor_theme = pd.DataFrame()
if not col_vendor:
    st.info("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ° â€” Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ ÑÑ‚Ñƒ ÑĞ²Ğ¾Ğ´ĞºÑƒ.")
else:
    try:
        vendor_theme = add_totals_crosstab(fdf[col_vendor], fdf["Ğ¢ĞµĞ¼Ğ°"], total_name="Ğ˜Ñ‚Ğ¾Ğ³Ğ¾")
        st.dataframe(vendor_theme, use_container_width=True, hide_index=True)
    except Exception as e:
        st.warning("ĞĞµ ÑĞ¼Ğ¾Ğ³ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ´ĞºÑƒ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸Ã—Ğ¢ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ» Ğ±Ñ‹ÑÑ‚Ñ€ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ±ĞµĞ· Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ².")
        # fallback (Ğ±ĞµĞ· Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²)
        vendor_theme = pd.crosstab(fdf[col_vendor].fillna("â€”").astype(str), fdf["Ğ¢ĞµĞ¼Ğ°"].fillna("â€”").astype(str)).reset_index().rename(columns={"index": "ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ"})
        st.dataframe(vendor_theme, use_container_width=True, hide_index=True)
        with st.expander("Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸"):
            st.code(str(e))

st.divider()

# =========================
# Monthly 2024-2025 summary (all data)
# =========================
st.markdown("#### Ğ’ÑĞµ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ¼ĞµÑÑÑ†Ğ°Ğ¼ (2024â€“2025)")
df_2425 = df[df["_dt"].dt.year.isin([2024, 2025])].copy()
month_range = pd.period_range("2024-01", "2025-12", freq="M")

monthly = (
    df_2425.dropna(subset=["_dt"])
          .groupby(df_2425["_dt"].dt.to_period("M"))
          .size()
          .reindex(month_range, fill_value=0)
)

monthly_table = pd.DataFrame([monthly.values], columns=monthly.index.astype(str))
monthly_table.insert(0, "ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ", "ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
st.dataframe(monthly_table, use_container_width=True, hide_index=True)

st.divider()

# =========================
# Top-5 stations (filtered)
# =========================
st.markdown("#### Ğ¢ĞĞŸ-5 Ğ­Ğ—Ğ¡ Ğ¿Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸ÑĞ¼ (Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ)")
top5 = pd.DataFrame()
if not col_station:
    st.info("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞĞ¾Ğ¼ĞµÑ€ Ğ­Ğ—Ğ¡ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ° â€” Ğ¢ĞĞŸ-5 Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½.")
else:
    top5 = (
        fdf.groupby(col_station)
           .size()
           .sort_values(ascending=False)
           .head(5)
           .rename("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
           .reset_index()
    )
    if col_vendor:
        vendor_map = (
            fdf.groupby(col_station)[col_vendor]
               .agg(lambda s: s.dropna().astype(str).mode().iloc[0] if len(s.dropna()) else "")
        )
        top5["ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ"] = top5[col_station].map(vendor_map)

    st.dataframe(top5, use_container_width=True, hide_index=True)
    st.bar_chart(top5.set_index(col_station)["ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])

st.divider()

# =========================
# Raw data (filtered) - safe display
# =========================
st.markdown("#### Ğ¡Ñ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (Ğ¿Ğ¾ÑĞ»Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²)")
show_cols: List[str] = []
for c in [auto_id, col_date, col_time, col_reason, "Ğ¢ĞµĞ¼Ğ°", col_station, col_vendor, col_note]:
    if c and c in fdf.columns and c not in show_cols:
        show_cols.append(c)
if not show_cols:
    show_cols = [c for c in fdf.columns if not str(c).startswith("_")]

# Sort safely
display_df = fdf.sort_values("_dt", ascending=False) if "_dt" in fdf.columns else fdf
st.dataframe(display_df[show_cols], use_container_width=True, hide_index=True)

# =========================
# Export
# =========================
st.markdown("### Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚")
d1, d2 = st.columns([1, 1])

with d1:
    st.download_button(
        "â¬‡ï¸ CSV (Ğ¿Ğ¾ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼)",
        data=display_df[show_cols].to_csv(index=False).encode("utf-8-sig"),
        file_name="ezs_filtered.csv",
        mime="text/csv",
    )

with d2:
    sheets: Dict[str, pd.DataFrame] = {
        "filtered": display_df[show_cols],
        "themes_filtered": theme_counts,
        "monthly_2024_2025": monthly_table,
    }
    if len(vendor_theme):
        sheets["vendor_theme_filtered"] = vendor_theme
    if len(top5):
        sheets["top5_filtered"] = top5

    st.download_button(
        "â¬‡ï¸ Excel (ÑĞ²Ğ¾Ğ´ĞºĞ°)",
        data=to_excel_bytes(sheets),
        file_name="ezs_dashboard_export.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

st.caption("v4: ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¾ + Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ 'Ğ²Ñ‹Ñ…Ğ¾Ğ´Ñ‹' Ğ¿Ñ€Ğ¸ Ğ»ÑĞ±Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ñ… (Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ°, Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğµ fallback-Ğ¸).")
