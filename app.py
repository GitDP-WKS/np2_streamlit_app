import json
import re
from io import BytesIO
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st


st.set_page_config(page_title="Ğ­Ğ—Ğ¡ â€” Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹", layout="wide")


DEFAULT_SHEET_ID = "1YN_8UtrZMqOTYZHaLzczwkkfocD-sS_wKrlSBmn-S50"
DEFAULT_GID = "2075524941"

DEFAULT_THEME_RULES = [
    {"theme": "ĞœĞ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ", "keywords": ["Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½", "Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶"]},
    {"theme": "Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞµÑÑĞ¸Ğ¸ / ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "keywords": ["Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚", "Ğ·Ğ°Ğ¿ÑƒÑĞº", "Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°", "ÑĞµÑÑĞ¸"]},
    {"theme": "ĞŸÑ€ĞµÑ€Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞµÑÑĞ¸Ğ¸", "keywords": ["Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°Ğ½", "ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ»ÑŒĞ½"]},
    {"theme": "ĞŸĞ»Ğ°Ñ‚ĞµĞ¶Ğ¸ / Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ", "keywords": ["Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½", "Ğ±Ğ°Ğ½ĞºĞ¾Ğ²ÑĞº", "Ğ±Ğ°Ğ»Ğ°Ğ½Ñ", "Ğ´ĞµĞ½ĞµĞ¶", "Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚"]},
    {"theme": "Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ/Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ", "keywords": ["Ğ½Ğ¸Ğ·ĞºĞ°Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ", "Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾", "Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚"]},
    {"theme": "ĞÑ„Ñ„Ğ»Ğ°Ğ¹Ğ½/ÑĞµÑ‚ÑŒ/Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ", "keywords": ["Ğ½Ğµ Ğ² ÑĞµÑ‚Ğ¸", "Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿", "Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³"]},
    {"theme": "ĞŸĞ°Ñ€ĞºĞ¾Ğ²ĞºĞ°/Ğ·Ğ°Ğ½ÑÑ‚Ğ¾", "keywords": ["Ğ¿Ğ°Ñ€ĞºĞ¾Ğ²", "Ğ·Ğ°Ğ½ÑÑ‚Ğ¾", "Ğ´Ğ²Ñ", "Ğ¿Ğ´Ğ´"]},
    {"theme": "ĞšĞ¾Ğ½Ğ½ĞµĞºÑ‚Ğ¾Ñ€Ñ‹/ĞºĞ½Ğ¾Ğ¿ĞºĞ°", "keywords": ["ĞºĞ¾Ğ½Ğ½ĞµĞºÑ‚Ğ¾Ñ€", "Ğ°Ğ²Ğ°Ñ€Ğ¸Ğ¹Ğ½", "ĞºĞ½Ğ¾Ğ¿Ğº"]},
    {"theme": "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ­Ğ—Ğ¡", "keywords": ["ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğº", "Ñ‚ĞµÑ€Ñ€Ğ¸Ñ‚Ğ¾Ñ€Ğ¸"]},
]


def gsheets_csv_url(sheet_id: str, gid: str) -> str:
    # Public export URL (works when sheet is shared "anyone with link" as Viewer)
    return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"


def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", str(s).strip()).lower()


def pick_col(columns: List[str], candidates: List[str]) -> Optional[str]:
    norm_cols = {_norm(c): c for c in columns}
    for cand in candidates:
        key = _norm(cand)
        if key in norm_cols:
            return norm_cols[key]
    # fallback: partial match
    for cand in candidates:
        key = _norm(cand)
        for n, orig in norm_cols.items():
            if key in n:
                return orig
    return None


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [re.sub(r"\s+", " ", str(c).strip()) for c in df.columns]
    return df


def parse_datetime(df: pd.DataFrame) -> Tuple[pd.DataFrame, str, str]:
    df = normalize_columns(df)

    col_date = pick_col(df.columns.tolist(), ["Ğ”Ğ°Ñ‚Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "Ğ”Ğ°Ñ‚Ğ°", "Date"])
    col_time = pick_col(df.columns.tolist(), ["Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "Ğ’Ñ€ĞµĞ¼Ñ", "Time", "Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ "])

    if col_date is None:
        raise ValueError("ĞĞµ Ğ½Ğ°ÑˆÑ‘Ğ» ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ Ñ Ğ´Ğ°Ñ‚Ğ¾Ğ¹. ĞĞ¶Ğ¸Ğ´Ğ°Ğ» 'Ğ”Ğ°Ñ‚Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ'.")

    # Ğ’ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ°Ñ… Ğ²Ñ€ĞµĞ¼Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼ â€” Ñ‚Ğ¾Ğ³Ğ´Ğ° ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ°Ñ‚Ñƒ
    if col_time is None:
        df["_dt"] = pd.to_datetime(df[col_date], dayfirst=True, errors="coerce")
        return df, col_date, ""

    df["_dt"] = pd.to_datetime(
        df[col_date].astype(str) + " " + df[col_time].astype(str),
        dayfirst=True,
        errors="coerce",
    )
    return df, col_date, col_time


def add_week(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    # ĞĞµĞ´ĞµĞ»Ñ Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾Ğ¼ Ğ² Ğ¿Ğ¾Ğ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¸Ğº
    df["_week_start"] = df["_dt"].dt.to_period("W-MON").dt.start_time
    df["_week_label"] = df["_week_start"].dt.strftime("%Y-%m-%d")
    return df


def classify_theme(reason: str, rules: List[Dict]) -> str:
    text = _norm(reason)
    for r in rules:
        theme = r.get("theme", "").strip() or "Ğ‘ĞµĞ· Ñ‚ĞµĞ¼Ñ‹"
        kws = r.get("keywords", [])
        if any(_norm(k) in text for k in kws if str(k).strip()):
            return theme
    return "Ğ”Ñ€ÑƒĞ³Ğ¾Ğµ"


def apply_themes(df: pd.DataFrame, reason_col: str, rules: List[Dict]) -> pd.DataFrame:
    df = df.copy()
    df["Ğ¢ĞµĞ¼Ğ°"] = df[reason_col].astype(str).apply(lambda x: classify_theme(x, rules))
    return df


@st.cache_data(ttl=600, show_spinner=False)
def load_data(sheet_id: str, gid: str) -> pd.DataFrame:
    url = gsheets_csv_url(sheet_id, gid)
    df = pd.read_csv(url)
    return df


def to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8-sig")


def to_excel_bytes(sheets: Dict[str, pd.DataFrame]) -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        for name, sdf in sheets.items():
            sdf.to_excel(writer, sheet_name=name[:31], index=False)
    return bio.getvalue()


st.title("ğŸ“Š Ğ­Ğ—Ğ¡ â€” Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹")

with st.sidebar:
    st.header("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
    sheet_id = st.text_input("Google Sheet ID", value=DEFAULT_SHEET_ID)
    gid = st.text_input("GID (Ğ»Ğ¸ÑÑ‚)", value=DEFAULT_GID)
    st.caption("Ğ’Ğ°Ğ¶Ğ½Ğ¾: Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ñ€Ğ°ÑÑˆĞ°Ñ€ĞµĞ½Ğ° ĞºĞ°Ğº â€œAnyone with the link â†’ Viewerâ€.")

    if st.button("ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ĞºÑÑˆ"):
        st.cache_data.clear()
        st.toast("ĞšÑÑˆ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½, Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµÑ‡Ğ¸Ñ‚Ğ°ÑÑ‚ÑÑ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾.", icon="âœ…")

    st.divider()
    st.header("Ğ¢ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸")
    rules_text = st.text_area(
        "ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° (JSON). ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ´ ÑĞµĞ±Ñ.",
        value=json.dumps(DEFAULT_THEME_RULES, ensure_ascii=False, indent=2),
        height=260,
    )

    try:
        theme_rules = json.loads(rules_text)
        if not isinstance(theme_rules, list):
            raise ValueError("JSON Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ¼ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ».")
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°Ñ… JSON: {e}")
        theme_rules = DEFAULT_THEME_RULES


# --- Load ---
try:
    raw = load_data(sheet_id, gid)
except Exception as e:
    st.error(
        "ĞĞµ ÑĞ¼Ğ¾Ğ³ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ. "
        "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ (Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€) Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Sheet ID / GID.\n\n"
        f"Ğ¢ĞµĞºÑÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {e}"
    )
    st.stop()

# --- Parse & normalize ---
df, col_date, col_time = parse_datetime(raw)

col_reason = pick_col(df.columns.tolist(), ["ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", "Ğ¢ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])
col_station = pick_col(df.columns.tolist(), ["ĞĞ¾Ğ¼ĞµÑ€ Ğ­Ğ—Ğ¡", "Ğ­Ğ—Ğ¡", "Station", "Ğ¡Ñ‚Ğ°Ğ½Ñ†Ğ¸Ñ"])
col_vendor = pick_col(df.columns.tolist(), ["ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ğ¸", "ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ", "Vendor"])
col_note = pick_col(df.columns.tolist(), ["ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ", "ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹", "Note"])
col_id = pick_col(df.columns.tolist(), ["â„–", "N", "No", "ĞĞ¾Ğ¼ĞµÑ€", "ID"])

if col_reason is None:
    st.error("ĞĞµ Ğ½Ğ°ÑˆÑ‘Ğ» ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ 'ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ'. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº Ğ½Ğ° Ğ»Ğ¸ÑÑ‚Ğµ.")
    st.stop()

df = add_week(df)
df = apply_themes(df, col_reason, theme_rules)

# --- Filters ---
st.subheader("Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")

min_dt = df["_dt"].min()
max_dt = df["_dt"].max()

c1, c2, c3, c4 = st.columns([1.2, 1.2, 1.2, 1.4])

with c1:
    # default: latest week
    latest_week = df["_week_label"].dropna().max()
    week_mode = st.radio("ĞŸĞµÑ€Ğ¸Ğ¾Ğ´", ["ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ½ĞµĞ´ĞµĞ»Ñ", "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ½ĞµĞ´ĞµĞ»Ğ¸", "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚"], horizontal=False)

with c2:
    if week_mode == "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ½ĞµĞ´ĞµĞ»Ğ¸":
        week = st.selectbox("ĞĞµĞ´ĞµĞ»Ñ (Ğ¿Ğ¾Ğ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¸Ğº)", sorted(df["_week_label"].dropna().unique())[::-1], index=0)
    else:
        week = latest_week

with c3:
    if week_mode == "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚":
        start_date = st.date_input("Ğ¡ Ğ´Ğ°Ñ‚Ñ‹", value=(min_dt.date() if pd.notna(min_dt) else None))
        end_date = st.date_input("ĞŸĞ¾ Ğ´Ğ°Ñ‚Ñƒ", value=(max_dt.date() if pd.notna(max_dt) else None))
    else:
        start_date, end_date = None, None

with c4:
    theme_filter = st.multiselect(
        "Ğ¢ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸",
        options=sorted(df["Ğ¢ĞµĞ¼Ğ°"].dropna().unique()),
        default=[],
        placeholder="Ğ’ÑĞµ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸",
    )

# manufacturer filter
if col_vendor is not None:
    vendors = sorted([v for v in df[col_vendor].dropna().unique()])
    vendor_filter = st.multiselect("ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ", options=vendors, default=[], placeholder="Ğ’ÑĞµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸")
else:
    vendor_filter = []

# Apply filters
fdf = df.copy()

if week_mode in ("ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ½ĞµĞ´ĞµĞ»Ñ", "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ½ĞµĞ´ĞµĞ»Ğ¸") and week:
    fdf = fdf[fdf["_week_label"] == week]

if week_mode == "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚" and start_date and end_date:
    # inclusive end date
    fdf = fdf[(fdf["_dt"] >= pd.to_datetime(start_date)) & (fdf["_dt"] < pd.to_datetime(end_date) + pd.Timedelta(days=1))]

if theme_filter:
    fdf = fdf[fdf["Ğ¢ĞµĞ¼Ğ°"].isin(theme_filter)]

if vendor_filter and col_vendor is not None:
    fdf = fdf[fdf[col_vendor].isin(vendor_filter)]

# --- KPIs ---
k1, k2, k3, k4 = st.columns(4)

total = int(len(fdf))
unique_stations = int(fdf[col_station].nunique()) if col_station is not None else 0
top_theme = (fdf["Ğ¢ĞµĞ¼Ğ°"].value_counts().index[0] if total else "â€”")
top_reason = (fdf[col_reason].value_counts().index[0] if total else "â€”")

k1.metric("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹", f"{total}")
k2.metric("Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ­Ğ—Ğ¡", f"{unique_stations}" if col_station else "â€”")
k3.metric("Ğ¢Ğ¾Ğ¿-Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°", top_theme)
k4.metric("Ğ§Ğ°ÑÑ‚Ğ°Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", top_reason)

st.divider()

# --- Charts & tables ---
left, right = st.columns([1.2, 1])

with left:
    st.markdown("#### Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ½ĞµĞ´ĞµĞ»ÑĞ¼")
    trend = (
        df.dropna(subset=["_week_start"])
          .groupby("_week_start")
          .size()
          .rename("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
          .reset_index()
          .sort_values("_week_start")
    )
    if len(trend):
        st.line_chart(trend.set_index("_week_start")["ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])
    else:
        st.info("ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°.")

with right:
    st.markdown("#### Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°Ğ¼ (Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ)")
    theme_counts = fdf["Ğ¢ĞµĞ¼Ğ°"].value_counts().rename_axis("Ğ¢ĞµĞ¼Ğ°").reset_index(name="ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
    st.dataframe(theme_counts, use_container_width=True, hide_index=True)
    if len(theme_counts):
        st.bar_chart(theme_counts.set_index("Ğ¢ĞµĞ¼Ğ°")["ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])

st.divider()

st.markdown("#### Ğ¢ĞĞŸ-5 Ğ­Ğ—Ğ¡ Ğ¿Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸ÑĞ¼ (Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ)")
if col_station is None:
    st.warning("ĞĞµ Ğ½Ğ°ÑˆÑ‘Ğ» ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ 'ĞĞ¾Ğ¼ĞµÑ€ Ğ­Ğ—Ğ¡' â€” Ğ¢ĞĞŸ-5 Ğ¿Ğ¾ ÑÑ‚Ğ°Ğ½Ñ†Ğ¸ÑĞ¼ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½.")
else:
    top5 = (
        fdf.groupby(col_station)
           .size()
           .sort_values(ascending=False)
           .head(5)
           .rename("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
           .reset_index()
    )
    if col_vendor is not None:
        # Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ (ÑĞ°Ğ¼Ñ‹Ğ¹ Ñ‡Ğ°ÑÑ‚Ñ‹Ğ¹ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ğ¸)
        vendor_map = (
            fdf.groupby(col_station)[col_vendor]
               .agg(lambda s: s.dropna().mode().iloc[0] if len(s.dropna().mode()) else "")
        )
        top5["ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ"] = top5[col_station].map(vendor_map)

    st.dataframe(top5, use_container_width=True, hide_index=True)

    # Ğ‘Ğ°Ñ€Ñ‡Ğ°Ñ€Ñ‚ Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ¿-5
    st.bar_chart(top5.set_index(col_station)["ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ"])

st.divider()

st.markdown("#### Ğ¡Ñ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (Ğ¿Ğ¾ÑĞ»Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²)")
show_cols = []
for c in [col_id, col_date, col_time, col_reason, "Ğ¢ĞµĞ¼Ğ°", col_station, col_vendor, col_note]:
    if c and c in fdf.columns and c not in show_cols:
        show_cols.append(c)
if not show_cols:
    show_cols = fdf.columns.tolist()

st.dataframe(fdf[show_cols].sort_values("_dt", ascending=False), use_container_width=True, hide_index=True)

# --- Downloads ---
st.markdown("### Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚")
d1, d2 = st.columns([1, 1])

with d1:
    st.download_button(
        "â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV (Ğ¿Ğ¾ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼)",
        data=to_csv_bytes(fdf[show_cols]),
        file_name="ezs_filtered.csv",
        mime="text/csv",
    )

with d2:
    # Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ»Ğ¸ÑÑ‚Ğ¾Ğ²: raw filtered + theme + top5
    sheets = {"filtered": fdf[show_cols]}
    sheets["themes"] = theme_counts
    if col_station is not None:
        sheets["top5"] = top5 if "top5" in locals() else pd.DataFrame()
    st.download_button(
        "â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Excel (ÑĞ²Ğ¾Ğ´ĞºĞ°)",
        data=to_excel_bytes(sheets),
        file_name="ezs_dashboard_export.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

st.caption("Ğ•ÑĞ»Ğ¸ Ñ…Ğ¾Ñ‡ĞµÑˆÑŒ â€” Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»Ñ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº â€œĞ¢ĞĞŸ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½â€ Ğ¸ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°Ñ‚ĞµĞ»ÑŒ â€œĞ¼ĞµÑÑÑ†/ĞºĞ²Ğ°Ñ€Ñ‚Ğ°Ğ»/Ğ³Ğ¾Ğ´â€.")
