import re
from io import BytesIO
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

st.set_page_config(page_title="Ğ­Ğ—Ğ¡ â€” Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ (2025)", layout="wide")

# ======== ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ ĞŸĞ Ğ£ĞœĞĞ›Ğ§ĞĞĞ˜Ğ® ========
DEFAULT_SHEET_ID = "1YN_8UtrZMqOTYZHaLzczwkkfocD-sS_wKrlSBmn-S50"
# Ğ¯Ğ½Ğ²Ğ°Ñ€ÑŒâ€“Ğ´ĞµĞºĞ°Ğ±Ñ€ÑŒ 2025 + Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ»Ğ¸ÑÑ‚ (ĞºĞ°Ğº Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸ÑĞ»Ğ°Ğ»)
DEFAULT_GIDS: List[str] = [
    "880054222","290665501","1707951068","1280453214","1898471504","1456377749",
    "100006210","1678514560","1664238791","1022163523","824830115","2075524941"
]

# ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ -> Ğ·Ğ°Ğ²Ğ¾Ğ´
DEFAULT_VENDOR_MAP: Dict[str, List[str]] = {
    "Ğ•ĞŸĞ ĞĞœ": ["ĞµĞ¿Ñ€Ğ¾Ğ¼", "eprom", "e-prom", "e prom"],
    "ĞĞ¡ĞŸ":   ["Ğ½ÑĞ¿", "nsp"],
}

# ======== Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• ========
def gsheets_csv_url(sheet_id: str, gid: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"

def norm(s: str) -> str:
    return re.sub(r"\s+", " ", str(s).strip()).lower()

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [re.sub(r"\s+", " ", str(c).strip()) for c in df.columns]
    return df

def pick_col(columns: List[str], candidates: List[str]) -> Optional[str]:
    if not columns:
        return None
    m = {norm(c): c for c in columns}
    for cand in candidates:
        k = norm(cand)
        if k in m:
            return m[k]
    # partial fallback
    for cand in candidates:
        k = norm(cand)
        for nk, orig in m.items():
            if k and k in nk:
                return orig
    return None

def vendor_to_plant(v: str, vendor_map: Dict[str, List[str]]) -> str:
    s = norm(v)
    if not s or s == "nan":
        return "â€”"
    for plant, keys in vendor_map.items():
        for k in keys:
            kk = norm(k)
            if kk and kk in s:
                return plant
    return "Ğ”Ñ€ÑƒĞ³Ğ¾Ğµ"

def parse_dt_smart(df: pd.DataFrame, col_date: str, col_time: Optional[str]) -> pd.Series:
    if col_time:
        s = df[col_date].astype(str) + " " + df[col_time].astype(str)
    else:
        s = df[col_date].astype(str)
    dt1 = pd.to_datetime(s, dayfirst=True, errors="coerce")
    ok1 = float(dt1.notna().mean())
    if ok1 >= 0.5:
        return dt1
    dt2 = pd.to_datetime(s, dayfirst=False, errors="coerce")
    ok2 = float(dt2.notna().mean())
    return dt2 if ok2 > ok1 else dt1

@st.cache_data(ttl=900, show_spinner=False)
def load_gid(sheet_id: str, gid: str) -> pd.DataFrame:
    url = gsheets_csv_url(sheet_id, gid)
    return pd.read_csv(url, on_bad_lines="skip")

def load_all(sheet_id: str, gids: List[str]) -> Tuple[pd.DataFrame, List[str]]:
    frames: List[pd.DataFrame] = []
    errors: List[str] = []
    for gid in gids:
        try:
            dfi = load_gid(sheet_id, gid)
            dfi["_source_gid"] = gid
            frames.append(dfi)
        except Exception as e:
            errors.append(f"GID {gid}: {e}")
    if not frames:
        return pd.DataFrame(), errors
    out = pd.concat(frames, ignore_index=True, sort=False)
    return out, errors

def add_totals(df: pd.DataFrame, row_name: str = "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾") -> pd.DataFrame:
    # df: rows x cols (Ñ‡Ğ¸ÑĞ»Ğ°)
    df2 = df.copy()
    df2[row_name] = df2.sum(axis=1)
    total_row = pd.DataFrame(df2.sum(axis=0)).T
    total_row.index = [row_name]
    return pd.concat([df2, total_row], axis=0)

# ======== UI ========
st.title("ğŸ“Š Ğ­Ğ—Ğ¡ â€” Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ (2025)")

with st.sidebar:
    st.header("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº (Google Sheets)")
    sheet_id = st.text_input("Sheet ID", value=DEFAULT_SHEET_ID)
    gids_text = st.text_area("GID Ğ»Ğ¸ÑÑ‚Ğ¾Ğ² (Ñ‡ĞµÑ€ĞµĞ· Ğ·Ğ°Ğ¿ÑÑ‚ÑƒÑ)", value=",".join(DEFAULT_GIDS), height=100)
    st.caption("Ğ’Ğ°Ğ¶Ğ½Ğ¾: Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ñ€Ğ°ÑÑˆĞ°Ñ€ĞµĞ½Ğ° ĞºĞ°Ğº â€œAnyone with the link â†’ Viewerâ€.")
    if st.button("ğŸ”„ Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ ĞºÑÑˆ"):
        st.cache_data.clear()
        st.toast("ĞšÑÑˆ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½.", icon="âœ…")

    st.divider()
    st.header("Ğ—Ğ°Ğ²Ğ¾Ğ´Ñ‹ (ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ)")
    st.caption("ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ: Ğ•ĞŸĞ ĞĞœ / ĞĞ¡ĞŸ. Ğ•ÑĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸ Ğ¿Ğ¸ÑˆÑƒÑ‚ÑÑ Ğ¸Ğ½Ğ°Ñ‡Ğµ â€” Ğ´Ğ¾Ğ¿Ğ¸ÑˆĞ¸ ĞºĞ»ÑÑ‡Ğ¸ Ğ² ĞºĞ¾Ğ´Ğµ Ğ¸Ğ»Ğ¸ ÑĞºĞ°Ğ¶Ğ¸ Ğ¼Ğ½Ğµ.")
    vendor_map = DEFAULT_VENDOR_MAP

gids = [g.strip() for g in str(gids_text).split(",") if g.strip()]
raw, errors = load_all(sheet_id, gids)

if errors:
    st.warning("ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ»Ğ¸ÑÑ‚Ñ‹ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ»Ğ¸ÑÑŒ â€” Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ğ» Ñ Ñ‚ĞµĞ¼Ğ¸, Ñ‡Ñ‚Ğ¾ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ.")
    with st.expander("ĞÑˆĞ¸Ğ±ĞºĞ¸ Ğ¿Ğ¾ Ğ»Ğ¸ÑÑ‚Ğ°Ğ¼"):
        st.code("\n".join(errors))

if raw.empty:
    st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ¸ Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¸ÑÑ‚Ğ°. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğ¸ Sheet ID/GID.")
    st.stop()

df = normalize_columns(raw)

# ======== Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ ========
cols = df.columns.tolist()
auto_date = pick_col(cols, ["Ğ”Ğ°Ñ‚Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "Ğ”Ğ°Ñ‚Ğ°", "Date"])
auto_time = pick_col(cols, ["Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "Ğ’Ñ€ĞµĞ¼Ñ", "Time"])
auto_reason = pick_col(cols, ["ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ", "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", "Problem", "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°/Ñ‚ĞµĞ¼Ğ°"])
auto_station = pick_col(cols, ["ĞĞ¾Ğ¼ĞµÑ€ Ğ­Ğ—Ğ¡", "Ğ­Ğ—Ğ¡", "Station", "Ğ¡Ñ‚Ğ°Ğ½Ñ†Ğ¸Ñ"])
auto_vendor = pick_col(cols, ["ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ğ¸", "ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ", "Vendor"])
auto_note = pick_col(cols, ["ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ", "ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹", "Note"])
auto_id = pick_col(cols, ["â„–", "N", "No", "ĞĞ¾Ğ¼ĞµÑ€", "ID"])

with st.expander("ğŸ› ï¸ Ğ¡Ğ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº (ĞµÑĞ»Ğ¸ Ğ°Ğ²Ñ‚Ğ¾ Ğ½Ğµ ÑƒĞ³Ğ°Ğ´Ğ°Ğ»)"):
    c1, c2 = st.columns(2)
    with c1:
        col_date = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ”ĞĞ¢Ğ", options=cols, index=(cols.index(auto_date) if auto_date in cols else 0))
        col_time = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ’Ğ Ğ•ĞœĞ¯ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols,
                                index=(1 + cols.index(auto_time) if auto_time in cols else 0))
        col_reason = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞŸĞ Ğ˜Ğ§Ğ˜ĞĞ (ĞºĞ°Ğº Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ)", options=cols,
                                  index=(cols.index(auto_reason) if auto_reason in cols else 0))
    with c2:
        col_station = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞĞĞœĞ•Ğ  Ğ­Ğ—Ğ¡ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols,
                                   index=(1 + cols.index(auto_station) if auto_station in cols else 0))
        col_vendor = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞŸĞ ĞĞ˜Ğ—Ğ’ĞĞ”Ğ˜Ğ¢Ğ•Ğ›Ğ¬ (Ğ´Ğ»Ñ Ğ·Ğ°Ğ²Ğ¾Ğ´Ğ¾Ğ²)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols,
                                  index=(1 + cols.index(auto_vendor) if auto_vendor in cols else 0))
        col_note = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° ĞŸĞ Ğ˜ĞœĞ•Ğ§ĞĞĞ˜Ğ• (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾)", options=["â€” Ğ½ĞµÑ‚ â€”"] + cols,
                                index=(1 + cols.index(auto_note) if auto_note in cols else 0))
    st.dataframe(df.head(10), use_container_width=True)

# normalize
col_time = None if col_time == "â€” Ğ½ĞµÑ‚ â€”" else col_time
col_station = None if col_station == "â€” Ğ½ĞµÑ‚ â€”" else col_station
col_vendor = None if col_vendor == "â€” Ğ½ĞµÑ‚ â€”" else col_vendor
col_note = None if col_note == "â€” Ğ½ĞµÑ‚ â€”" else col_note

if not col_date or col_date not in df.columns:
    st.error("ĞĞµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ´Ğ°Ñ‚Ñ‹.")
    st.stop()
if not col_reason or col_reason not in df.columns:
    st.error("ĞĞµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹.")
    st.stop()

df["_dt"] = parse_dt_smart(df, col_date, col_time)
if df["_dt"].isna().all():
    st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ñ‹ (Ğ²ÑĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ). ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ´Ğ°Ñ‚Ñ‹/Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸.")
    st.stop()

if col_vendor and col_vendor in df.columns:
    df["Ğ—Ğ°Ğ²Ğ¾Ğ´"] = df[col_vendor].astype(str).apply(lambda x: vendor_to_plant(x, vendor_map))
else:
    df["Ğ—Ğ°Ğ²Ğ¾Ğ´"] = "â€”"

# ======== Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ ========
st.subheader("Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
f1, f2, f3, f4 = st.columns([1.2, 1.2, 1.4, 1.2])

# Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ 2025 Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
df_2025 = df[df["_dt"].dt.year == 2025].copy()
if df_2025.empty:
    st.warning("Ğ’ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½ĞµÑ‚ 2025 Ğ³Ğ¾Ğ´Ğ° (Ğ¸Ğ»Ğ¸ Ğ´Ğ°Ñ‚Ñ‹ Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ğ»Ğ¸ÑÑŒ ĞºĞ°Ğº 2025). ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ²ÑÑ‘, Ñ‡Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ.")
    df_2025 = df.copy()

min_d = df_2025["_dt"].min().date()
max_d = df_2025["_dt"].max().date()

with f1:
    period_mode = st.radio("ĞŸĞµÑ€Ğ¸Ğ¾Ğ´", ["Ğ’ĞµÑÑŒ 2025", "ĞœĞµÑÑÑ†", "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½"], horizontal=False)
with f2:
    if period_mode == "ĞœĞµÑÑÑ†":
        month = st.selectbox("ĞœĞµÑÑÑ†", [f"2025-{m:02d}" for m in range(1, 13)], index=0)
    else:
        month = None
with f3:
    if period_mode == "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½":
        start_date = st.date_input("Ğ¡ Ğ´Ğ°Ñ‚Ñ‹", value=min_d)
        end_date = st.date_input("ĞŸĞ¾ Ğ´Ğ°Ñ‚Ñƒ", value=max_d)
    else:
        start_date, end_date = None, None
with f4:
    plant_filter = st.multiselect("Ğ—Ğ°Ğ²Ğ¾Ğ´", options=sorted(df_2025["Ğ—Ğ°Ğ²Ğ¾Ğ´"].unique()),
                                  default=[p for p in ["Ğ•ĞŸĞ ĞĞœ","ĞĞ¡ĞŸ"] if p in set(df_2025["Ğ—Ğ°Ğ²Ğ¾Ğ´"].unique())])

fdf = df_2025.copy()
if period_mode == "ĞœĞµÑÑÑ†" and month:
    fdf = fdf[fdf["_dt"].dt.to_period("M").astype(str) == month]
elif period_mode == "Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½" and start_date and end_date:
    start = pd.to_datetime(start_date)
    end = pd.to_datetime(end_date) + pd.Timedelta(days=1)
    fdf = fdf[(fdf["_dt"] >= start) & (fdf["_dt"] < end)]

if plant_filter:
    fdf = fdf[fdf["Ğ—Ğ°Ğ²Ğ¾Ğ´"].isin(plant_filter)]

# ======== KPI ========
k1, k2, k3, k4 = st.columns(4)
total = int(len(fdf))
uniq_station = int(fdf[col_station].nunique()) if col_station else 0
k1.metric("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹", total)
k2.metric("Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ­Ğ—Ğ¡", uniq_station if col_station else "â€”")
k3.metric("Ğ•ĞŸĞ ĞĞœ", int((fdf["Ğ—Ğ°Ğ²Ğ¾Ğ´"] == "Ğ•ĞŸĞ ĞĞœ").sum()) if total else 0)
k4.metric("ĞĞ¡ĞŸ", int((fdf["Ğ—Ğ°Ğ²Ğ¾Ğ´"] == "ĞĞ¡ĞŸ").sum()) if total else 0)

st.divider()

# ======== 1) ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° x Ğ—Ğ°Ğ²Ğ¾Ğ´ ========
st.markdown("### Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°Ğ¼ Ã— Ğ·Ğ°Ğ²Ğ¾Ğ´ (Ğ•ĞŸĞ ĞĞœ / ĞĞ¡ĞŸ)")
reason_x_plant = pd.crosstab(
    fdf[col_reason].fillna("â€”").astype(str),
    fdf["Ğ—Ğ°Ğ²Ğ¾Ğ´"].fillna("â€”").astype(str),
    dropna=False,
)

# Ñ„Ğ¸ĞºÑĞ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ±Ñ‹Ğ»Ğ¸ Ğ•ĞŸĞ ĞĞœ/ĞĞ¡ĞŸ)
for col in ["Ğ•ĞŸĞ ĞĞœ","ĞĞ¡ĞŸ","Ğ”Ñ€ÑƒĞ³Ğ¾Ğµ","â€”"]:
    if col not in reason_x_plant.columns:
        reason_x_plant[col] = 0
reason_x_plant = reason_x_plant[["Ğ•ĞŸĞ ĞĞœ","ĞĞ¡ĞŸ","Ğ”Ñ€ÑƒĞ³Ğ¾Ğµ","â€”"]]
reason_x_plant = add_totals(reason_x_plant, row_name="Ğ˜Ñ‚Ğ¾Ğ³Ğ¾")

view_reason = reason_x_plant.reset_index().rename(columns={col_reason: "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", "index": "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°"})
st.dataframe(view_reason, use_container_width=True, hide_index=True)

st.divider()

# ======== 2) ĞŸĞ¾Ğ¼ĞµÑÑÑ‡Ğ½Ğ¾ 2025 (Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ»Ğ¸ÑÑ‚Ğ°Ğ¼, Ğ½Ğµ Ğ¿Ğ¾ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼) ========
st.markdown("### Ğ’ÑĞµ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ¼ĞµÑÑÑ†Ğ°Ğ¼ 2025 (Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ»Ğ¸ÑÑ‚Ğ°Ğ¼)")
all_2025 = df[df["_dt"].dt.year == 2025].copy()
pr = pd.period_range("2025-01", "2025-12", freq="M")
monthly = (
    all_2025.dropna(subset=["_dt"])
           .groupby(all_2025["_dt"].dt.to_period("M"))
           .size()
           .reindex(pr, fill_value=0)
)
monthly_table = pd.DataFrame([monthly.values], columns=[p.strftime("%Y-%m") for p in pr])
monthly_table.insert(0, "ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ", "ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
st.dataframe(monthly_table, use_container_width=True, hide_index=True)

st.divider()

# ======== 3) Ğ¢ĞĞŸ-5 Ğ­Ğ—Ğ¡ ========
st.markdown("### Ğ¢ĞĞŸ-5 Ğ­Ğ—Ğ¡ Ğ¿Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸ÑĞ¼ (Ğ¿Ğ¾ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼)")
if not col_station:
    st.info("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° 'ĞĞ¾Ğ¼ĞµÑ€ Ğ­Ğ—Ğ¡' Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° â€” Ğ¢ĞĞŸ-5 Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½.")
    top5_view = pd.DataFrame()
else:
    top5 = (
        fdf.groupby(col_station)
           .size()
           .sort_values(ascending=False)
           .head(5)
           .rename("ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ")
           .reset_index()
    )
    plant_mode = (
        fdf.groupby(col_station)["Ğ—Ğ°Ğ²Ğ¾Ğ´"]
           .agg(lambda s: s.dropna().astype(str).mode().iloc[0] if len(s.dropna()) else "â€”")
    )
    top5["Ğ—Ğ°Ğ²Ğ¾Ğ´"] = top5[col_station].map(plant_mode)
    top5_view = top5
    st.dataframe(top5_view, use_container_width=True, hide_index=True)

st.divider()

# ======== Ğ¡Ñ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ========
st.markdown("### Ğ¡Ñ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (Ğ¿Ğ¾ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼)")
show_cols = []
for c in [auto_id, col_date, col_time, col_reason, "Ğ—Ğ°Ğ²Ğ¾Ğ´", col_station, col_vendor, col_note, "_source_gid"]:
    if c and c in fdf.columns and c not in show_cols:
        show_cols.append(c)

display_df = fdf.sort_values("_dt", ascending=False)
st.dataframe(display_df[show_cols], use_container_width=True, hide_index=True)

# ======== Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ ========
st.markdown("### Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚")
d1, d2 = st.columns(2)

with d1:
    st.download_button(
        "â¬‡ï¸ CSV (Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)",
        data=display_df[show_cols].to_csv(index=False).encode("utf-8-sig"),
        file_name="ezs_filtered_2025.csv",
        mime="text/csv",
    )

with d2:
    from io import BytesIO
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as w:
        view_reason.to_excel(w, sheet_name="reason_x_plant", index=False)
        monthly_table.to_excel(w, sheet_name="monthly_2025", index=False)
        if len(top5_view):
            top5_view.to_excel(w, sheet_name="top5", index=False)
        display_df[show_cols].to_excel(w, sheet_name="raw_filtered", index=False)
    st.download_button(
        "â¬‡ï¸ Excel (ÑĞ²Ğ¾Ğ´ĞºĞ°)",
        data=bio.getvalue(),
        file_name="ezs_dashboard_2025.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

st.caption("Ğ›Ñ‘Ğ³ĞºĞ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ Ğ±ĞµÑ€ÑƒÑ‚ÑÑ 1-Ğ²-1 Ğ¸Ğ· Google Sheets; Ğ·Ğ°Ğ²Ğ¾Ğ´ = Ğ•ĞŸĞ ĞĞœ/ĞĞ¡ĞŸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ; Ğ¼ĞµÑÑÑ†Ñ‹ 2025 ÑÑ‡Ğ¸Ñ‚Ğ°ÑÑ‚ÑÑ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¼ GID.")
